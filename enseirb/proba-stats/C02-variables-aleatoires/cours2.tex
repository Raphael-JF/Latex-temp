\input{../../stock/en-tete_v5.tex}
\usepackage{dsfont}

\newcounter{chapitre}
\setcounter{chapitre}{2}

\title{\Large Chapitre 2 \\ \Huge Vecteurs aléatoires}

\begin{document}
\input{../../stock/commands.tex}
\maketitle


\newcommand{\tribu}[0]{\mathcal{T}}
\newcommand{\univ}[0]{\Omega}
\newcommand{\proba}[0]{\mathbb{P}}
\newcommand{\probaset}[1]{\mathbb{P}\big(\{#1\}\big)}



\section{Introduction}
\begin{definition}{}{variable aléatoire}
    Soit $(\univ, \tribu, \proba)$ un espace de probabilité. On appelle \notion{vecteur aléatoire} sur $\univ$ une application de $\univ$ dans $\R^n$.
    Pour $n=1$, on parle de \notion{variable aléatoire}.
\end{definition}

\begin{remarque}{}{notation associée}
    Pour $A \in \R^n$, on notera $\{X \in A\}$ l'évènement~:
    $$\{\omega \in \univ,\, X(\omega) \in A\}$$
\end{remarque}

\begin{definition}{}{vecteur aléatoire discret}
    Soit $(\univ, \tribu, \proba)$ un espace de probabilité. Un vecteur aléatoire $X$ sur $\Omega$ est dit \notion{discret} s'il existe $F \subset \R^n$ au plus dénombrable tel que~:
    $$\proba\Bigl(\{X \in F\}\Bigr) = 1$$
    
\end{definition}


Nous émettrons dans le cadre du cours l'hypothèse suivante.
\begin{remarque}{}{en lien avec la définition}
    Si $X$ est un vecteur aléatoire sur $(\univ, \tribu, \proba)$, pour tout ouvert $A$ de $\R^n$~:
    $$\{\omega \in \univ,\, X(\omega) \in A\} = \{X \in A\} \in \tribu$$
\end{remarque}

\begin{definition}{}{vecteur aléatoire à densité}
    $X$ est un vecteur aléatoire définie sur $(\univ,\, \tribu,\, \proba)$ à valeurs dans $F$ s'il il existe $p : F \to \R_+$ qui vérifie pour tout $A$ ouvert de $F$~:
    $$\proba\Big(\{X \in A\}\Big) = \int_A p(x)\d{x}$$
\end{definition}

\begin{remarque}{}{à ce propos}
    Pour $A = F$,\, la probabilité précédemment évoquée vaut~:
    $$\probaset{X \in F} = 1$$
\end{remarque}
\section{Lois usuelles}

\begin{definition}{}{loi d'une variable aléatoire}
    La loi d'une variable aléatoire discrète $X$ à valeurs dans $F$ (\ie $\proba\Big(\{X \in F\}\Big)=1$) est entièrement définie par la famille de réels positifs~:
    $$\Bigg(\probaset{X = x}\Bigg)_{x \in F}$$
    de somme 1.
\end{definition}

\begin{exemple}{}{loi de Bernoulli}
    Pour une loi de Bernoulli~:
    \begin{itemize}
        \item $\displaystyle F = \{0, 1\}$
        \item $\displaystyle \probaset{X = 1} = p$ et $\probaset{X = 0} = 1-p$
    \end{itemize}
    Une telle variable aléatoire mesure la probabilité de succès d'une épreuve de Bernoulli (succès de probabilité $p$, échec de probabilité $1-p$).
\end{exemple}

\begin{exemple}{}{loi binomiale}
    Pour une loi binomiale~:
    \begin{itemize}
        \item $\displaystyle F = \intint{0}{n}$ où $n \in \N^*$
        \item $\displaystyle \forall k \in \intint{0}{n},\, \probaset{X = k} = \binom{n}{k}p^k(1-p)^{n-k}$
    \end{itemize}
    Une telle variable aléatoire mesure le nombre de succès au terme de la répétition indépendante de $n$ épreuves de Bernoulli du même paramètre $p$.
\end{exemple}

\begin{exemple}{}{loi géométrique}
    Pour une loi géométrique~:
    \begin{itemize}
        \item $\displaystyle F = \N^*$.
        \item $\displaystyle \forall k \in \N^*,\, \probaset{X = k} = p (1-p)^{k-1}$
    \end{itemize}
    En numérotant à partir de 1 une suite d'épreuves de Bernoulli répétées indépendamment et indéfiniment, une telle variable aléatoire mesure l'indice du premier succès. 
\end{exemple}

\begin{exemple}{}{loi de Poisson}
    Pour une loi de Poisson~:
    \begin{itemize}
        \item $\displaystyle F = \N$
        \item $\displaystyle \forall k \in \N,\, \probaset{X = k} = \frac{\lambda^k}{k!}e^{-\lambda}$
        
    \end{itemize}
    Une loi de Poisson a des intérêts multiples, comme celui d'approximer sous certaines conditions une loi binomiale.
\end{exemple}

\begin{remarque}{}{sur ces lois}
    On retrouve par dénombrement l'expression de telles lois. Par exemple dans le cas de la loi géométrique, $\{X = k\}$ correspond à l'évènement "La $k$-ème épreuve est la première à réussir.". Cela revient à avoir vu échouer les $k-1$ épreuves précédentes~:
    $$\probaset{X = k} = p (1-p)^{k-1}$$
\end{remarque}


\section{Lois marginales}

\begin{proposition}{}{formule des lois marginales}
    Soit $X$ et $Y$ deux vecteurs aléatoires discrètes sur $(\univ, \tribu, \proba)$, respectivement à valeurs dans $F$ et $G$. On a~:
    \begin{enumeratebf}
        \item $\displaystyle \forall x \in F,\, \probaset{X=x} = \sum_{g \in G}\probaset{Y = g}$
        \item $\displaystyle \forall g \in G,\, \probaset{Y=g} = \sum_{x \in F}\probaset{X = x}$
    \end{enumeratebf}
\end{proposition}

\begin{remarque}{}{démonstration}
    On doit ceci à la formule des probabilités totales appliquée aux systèmes complets d'évènements $\Big( Y=g \Big)_{g \in G}$ et $\Big( X=x \Big)_{x \in F}$.
\end{remarque}

\section{Variables aléatoires à densité}

Pour une \notion{variable aléatoire à densité}, on dira que la densité caractérise la loi de cette variable aléatoire~:

\begin{definition}{}{variable aléatoire à densité}
    Soit $X$ est une variable aléatoire sur $(\univ, \tribu, \proba)$ à valeurs dans $F$.
    $X$ est qualifiée de \notion{variable aléatoire à densité} s'il existe $p : F \to \seg{0}{1}$, dite \notion{densité de probabilité}, vérifiant pour toute partie $A$ de $F$~:
    $$\probaset{X \in A} = \int_A p(t)\d{t}$$
\end{definition}

\begin{remarque}{}{sur cette définition}
    La donnée de $X$ est alors entièrement caractérisée par sa densité de probabilité $p$.
\end{remarque}

\begin{exemple}{}{loi de densité uniforme}
    Pour une loi uniforme de paramètres $a<b$ dans $\R$~:
    \begin{itemize}
        \item $\displaystyle F = \seg{a}{b}$
        \item $\displaystyle \forall x \in \seg{a}{b},\, \probaset{X = x} = \frac{\mathds{1}_{\seg{a}{b}}(x)}{b-a}$
    \end{itemize}
    La fonction \code{rand} en \code{C} suit une loi uniforme sur $\seg{0}{1}$.
\end{exemple}

\begin{exemple}{}{loi de densité gaussienne}
    Pour une loi gaussienne de paramètres $\mu \in \R$ et $\sigma > 0$~:
    \begin{itemize}
        \item $\displaystyle F = \R$
        \item $\displaystyle \forall x \in \seg{a}{b},\, p(x) = \frac1{\sigma \sqrt{2\pi}}\operatorname \exp\Bigg(-\frac12\left(\frac{x-\mu}{\sigma}\right)^2\Bigg)$
    \end{itemize}
\end{exemple}


\begin{exemple}{}{loi de densité exponentielle}
    Pour une loi exponentielle de paramètre $\lambda > 0$~:
    \begin{itemize}
        \item $\displaystyle F = \R$
        \item $\displaystyle \forall x \in \R,\, p(x) = \lambda e^{-\lambda x} \mathds{1}_{\R_+}(x)$
    \end{itemize}
\end{exemple}

\begin{proposition}{}{formule des lois marginales de densité}
    Soit $(X,Y)$ un couple de variables aléatoires à densité sur $(\univ, \tribu, \proba)$ à valeurs dans $F\times G$. On note $p_{(X,Y)}$ la densité de probablité du couple $(X,Y)$. \\ Alors $p_X$ et $p_Y$ vérifient~:
    \begin{enumeratebf}
        \item $\displaystyle \forall x \in F,\,  p_X(x) = \int_\R p_{(X,Y)}(x,y)\d{y}$
        \item $\displaystyle \forall y \in G,\,  p_Y(y) = \int_\R p_{(X,Y)}(x,y)\d{x}$
    \end{enumeratebf}
\end{proposition}

\begin{demonstration}
    On montre le premier résultat. Montrons que~:
    $$\forall x \in \R,\,  p_X(x) = \int_\R p_{(X,Y)(x,y)\d{y}}$$
    Ce qui revient par définition à montrer que~:
    $$\forall A \subset F,\, \probaset{X \in A} = \int_A \underbrace{\int_\R p_{(X,Y)}(x,y)\d{y}}_{:=p_X(x)} \d{x}$$
    Soit $A \subset F$. On a~:
    \begin{align*}
        \proba(X \in A) &= \proba\Big((X,Y) \in A \times G\Big)\\
        &= \int_{A \times G} p_{(X,Y)}(x,y)\d{(x,y)} \\
        &= \int_A \Bigg(\int_G p_{(X,Y)}(x,y)\d{y}\Bigg)\d{x}
    \end{align*}
    D'où le résultat.
\end{demonstration}


\section{Espérance d'une variable aléatoire}
\subsection{Variable aléatoire discrète}

\begin{definition}{}{famille sommable de réels positifs}
    On dit qu’une \notion{famille $(u_i)_{i \in I}$ de nombres réels positifs est sommable} lorsqu’il existe $M\geq 0$ tel que, pour toute partie finie $J \subset I$ , on ait $\sum_{j \in J}u_j \leq M$.
    On définit alors \notion{la somme de la famille} par~:
    $$\sum_{i \in I}u_i = \sup_{\substack{J \subset I \\ J\text{ finie}}} \sum_{j \in J} u_j$$
\end{definition}

\begin{definition}{}{espérance d'une variable aléatoire discrète}
    Soit $X$ une variable aléatoire discrète à valeurs dans $F \subset \R$.
    $X$ est dite \notion{sommable} si elle admet un moment d'ordre 1 \ie si la famille $\Big(x\probaset{X = x}\Big)_{x \in X}$ est sommable. On notera alors $\mb{E}(X)$ son espérance définie ainsi~:
    $$\mb{E}(X) = \sum_{x \in F} x\probaset{X = x}$$
    
\end{definition}

\begin{exemple}{}{espérance d'une fonction indicatrice}
    Si $A$ est un évènement de $\univ$, alors $\mathds{1}_A : \univ \to \{0, 1\}$ est une variable aléatoire sommable (car $\mathds{1}_A(\univ)$ est fini). Puis~:
    $$\mb{E}(\mathds{1}_A) = \proba(A)$$
\end{exemple}

\begin{theoreme}{}{formule de transfert pour une variable aléatoire discrète}
    Soit $X$ une variable aléatoire discrète sommable à valeurs dans $F \subset \R$ et $g : F \to G$. Alors $g(X)$ est également une variable aléatoire sommable et~:
    $$\mb{E}\Big(g(X)\Big) = \sum_{x \in F}g(x)\probaset{X = x}$$
\end{theoreme}

\subsection{variable aléatoire à densité}

\begin{definition}{}{intégrabilité d'une variable aléatoire à densité}
    Soit $X$ une variable aléatoire à densité à valeurs dans $F$ un espace vectoriel de dimension $n$. On dit de $X$ qu'elle est \notion{intégrable} si l'intégrale~:
    $$\int_F \norme{x} p(x) \d{x}$$
    converge. Le cas échéant on dit que $X$ admet une espérance $\mb{E}(X)$ vérifiant~:
    $$\mb{E}(X) = \underbrace{\int_F \underbrace{x}_{\in F} \underbrace{p(x)}_{\in \R_+}\d{x}}_{\in F}$$
\end{definition}

\begin{remarque}{}{sur cette définition}
    Il est commun d'avoir $F = \R$ muni de la valeur absolue classique ou $F = \R^n$ peu importe la norme (\textit{cf.} dimension finie).
\end{remarque}

\subsection{exemples}


\begin{exemple}{}{espérance d'une loi de Bernoulli}
    Si $X$ suit une loi de Bernoulli de paramètre $p \in \seg{0}{1}$, alors $X(\Omega) = \{0, 1\}$ est fini, $X$ est donc sommable et~:
    \begin{align*}
        \mb{E}(X) &= 0 \times (1-p) + 1 \times p \\
        &= p
    \end{align*}
\end{exemple}

\begin{exemple}{}{espérance d'une loi binomiale}
    Si $X$ suit une loi binomiale de paramètres $n \in \N^*$ et $p \in \seg{0}{1}$, alors $X(\Omega) = \intint{0}{n}$ est fini, $X$ est donc sommable et~:
    \begin{align*}
        \mb{E}(X) &= \sum_{k=1}^n k \binom{n}{k} p^k (1-p)^{n-k} \qquad &\text{premier terme nul}\\
        &= \sum_{k=1}^n \frac{n!}{(k-1)!(n-k)!} p^k (1-p)^{n-k} \\
        &= np \sum_{k=1}^n \frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1} (1-p)^{n-k} \\
        &= np \sum_{j=0}^{n-1} \frac{(n-1)!}{j!(n-j-1)!} p^j (1-p)^{n-1-j}\qquad &\text{changement d'indice}\\
        &= np \Big(p + (1-p)\Big)^{n-1} \qquad &\text{formule du binôme de Newton}\\
        &= np
    \end{align*}
    d'où le résultat.
\end{exemple}

\begin{exemple}{}{espérance d'une loi de Poisson}
    Si $X$ suit une loi de Poisson de paramètres $n \in \N^*$ et $p \in \seg{0}{1}$, alors $X(\Omega) = \N$ est dénombrable, $X$ est donc sommable seulement si la quantité suivante admet une limite finie quand $N$ tend vers $+\infty$~:

    \begin{align*}
        \sum_{k=1}^N k \frac{\lambda^k}{k!}e^{-\lambda}\\
        &= \sum_{k=1}^N \frac{\lambda^k}{(k-1)!}e^{-\lambda}\\
        &= \lambda e^{-\lambda} \sum_{k=1}^N \frac{\lambda^{k-1}}{(k-1)!}\\
        &= \lambda e^{-\lambda} \sum_{j=0}^{N-1} \frac{\lambda^j}{j!}\\
        &\xrightarrow[N \to +\infty]{} \lambda e^{-\lambda} e^{\lambda} = \lambda
    \end{align*}
    $X$ est donc effectivement sommable, et son espérance vaut~:
    $$\mb{E}(X) = \lambda$$
\end{exemple}

\begin{exemple}{}{espérance d'une loi géométrique}
    Si $X$ suit une loi de géométrique de paramètre $p \in ]0; 1[$ (on évite les cas pathologiques), alors $X(\Omega) = \N$ est dénombrable, $X$ est donc sommable seulement si la quantité suivante admet une limite finie quand $N$ tend vers $+\infty$~:

    \begin{align*}
        \sum_{k=1}^N k p (1-p)^{k-1}\\
        &= p \sum_{k=1}^N k (1-p)^{k-1}\\
    \end{align*}
    Ceci implique la dérivée d'une somme    géométrique de raison $(1-p)$, valant~:
    $$\sum_{k=0}^{+\infty} (1-p)^k = \frac{1}{1-(1-p)} = \frac{1}{p}$$
    Par dérivation terme à terme on a bien sommabilité de $X$, et on trouve~:
    $$\mb{E}(X) = p\sum_{k=1}^{+\infty} k (1-p)^{k-1} = \frac{1}{p}$$
\end{exemple}




\section{Indépendance de variables aléatoires}

\begin{definition}{}{indépendance de variables aléatoires}
    Soit $X$ et $Y$ une famille de variables aléatoires sur $(\univ, \tribu, \proba)$ à valeurs dans $F$ et $G$ respectivement. On dit que $X$ et $Y$ sont \notion{indépendantes} si pour tous $x \in F$ et $y \in G$~:
    $$\probaset{X = x} = \probaset{x_j}\probaset{X_j = x_j}$$
    
\end{definition}


\section*{Questions de cours}

\begin{enumeratebf}
    \item Lois discrètes usuelles (de Bernoulli, binomiale, géométrique, de Poisson)
    \item Lois de densité usuelles 
    \item Espérance d'une variable aléatoire discrète
\end{enumeratebf}

$$v_n = \left( 1 + \frac{2}{\sqrt{5}}\right)\varphi^n+ \left( 1 - \frac{2}{\sqrt{5}}\right) \phi^n - 2$$

\begin{cases*}
    \varphi = \frac{1+\sqrt{5}}{2} & le nombre d'or\\
    \phi = \frac{1-\sqrt{5}}{2} = 1 - \varphi = -\frac{1}{\varphi}
\end{cases*}

$$v_n = \begin{cases*}
    0 &si $n=0$\\
    1 &si $n=1$\\
    v_{n-1} + v_{n-2} + 2 &si $n \geq 2$
\end{cases*}$$

$$x^n = \begin{cases*}
    1 &si $n=0$\\
    x^{\frac{n}{2}} \times x^{\frac{n}{2}} &si $n$ est pair\\
    x^{\frac{n-1}{2}} \times x^{\frac{n-1}{2}} \times x &si $n$ est impair
\end{cases*}$$

\end{document}