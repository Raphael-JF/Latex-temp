\input{../../stock/en-tete_v4.tex}
\begin{document}
\begin{adjustwidth}{-3cm}{-3cm}
\input{../../stock/commands.tex}

\begin{definition}{6.1}{algorithme probabiliste}
    Un algorithme est dit \notion{probabiliste} s'il effectue au moins un \notion{choix aléatoire entraînant une variation comportementale}.
\end{definition}

\begin{definition}{6.2}{algorithme déterministe}
    Un algorithme est dit \notion{déterministe} s'il est non probabiliste : son comportement est toujours le même pour une même entrée.
\end{definition}

\begin{definition}{6.3}{algorithme de Las Vegas}
    Un algorithme probabiliste est dit \notion{de Las Vegas} si : 
    \begin{itemize}
        \item il renvoie toujours une solution correcte ;
        \item son temps d'exécution est régi par une variable aléatoire.
    \end{itemize}
\end{definition}

\begin{definition}{6.4}{loi géométrique}
    Une \notion{loi géométrique de paramètre $p$} est une loi modélisant le \notion{nombre d'essais nécessaires jusqu'au premier succès} dans une suite d'expériences indépendantes identiques. Si $X$ suit une loi géométrique, alors~:
    $$\forall k \in \N^*,\, \mb{P}(X = k) = (1-p)^{k-1} p$$
    On a alors $\displaystyle \mb{E}(X) = \frac{1}{p}$ et $\displaystyle \mb{V}(X) = \frac{1-p}{p^2}$.
\end{definition}

\begin{implementation}{exemple d'algorithme de Las Vegas}
    \begin{lstC}
    int las_vegas(int* t, int taille){
        while(true) {
            int k = rand() % taille;
            if (t[k] == 1){
                return k;
            }
        }
    }
    \end{lstC}
\end{implementation}

\begin{definition}{6.5}{algorithme de Monte Carlo}
    Un algorithme probabiliste est dit \notion{de Monte Carlo} si~: 
    \begin{itemize}
        \item il renvoie sous une certaine probabilité une solution correcte ;
        \item son temps d'exécution est constant, indépendant des choix aléatoires. 
    \end{itemize}
\end{definition}

\begin{implementation}{exemple d'algorithme de Monte Carlo}
    \begin{lstC}
    int monte_carlo(int* t, int taille) {
        for (int i = 0; i < 300; i++){
            int k = rand() % taille;
            if (t[k] == 1){
                return k;
            }
        }
        return -1;
    }
    \end{lstC}
\end{implementation}

\begin{definition}{6.6}{deux types d'algorithmes Monte Carlo pour un problème de décision}
    Pour un problème de décision (dont la réponse est Vrai ou Faux), on distingue deux catégories d'algorithmes Monte Carlo~: 
    \begin{enumeratebf}
        \item \notion{À erreur unilatérale} : pour toute entrée de sortie attendue Vrai, l'algorithme renvoie Vrai presque sûrement (avec une probabilité de 1) et pour une entrée de sortie attendue Faux, l'algorithme renvoie Vrai avec une probabilité non nulle.
        \item \notion{À erreur bilatérale} : il existe une entrée de sortie attendue Vrai, pour laquelle l'algorithme renvoie Faux avec une probabilité non nulle.
    \end{enumeratebf}
\end{definition}

\begin{definition}{6.7}{problème d'optimisation}
    Un problème d'optimisation est défini pour un \notion{ensemble $I$ d'instances} : les entrées possibles. \\
    À toute instance $i \in I$ on associe un \notion{ensemble $S_i$ de solutions possibles}. \\
    À un problème d'optimisation on peut définir une \notion{fonction $f:\bigcup_{i \in I} \to \R_+$ de coût} que l'on cherche soit à minimiser soit à maximiser.\\\\
    Pour une instance $i \in I$, on cherche $s_\mr{opt} \in S_i$ une solution au coût optimal~:
    $$\begin{cases*}
        \forall s \in S_i,\, f(s) \leq f(s_\mr{opt}) &pour de la maximisation \\
        \forall s \in S_i,\, f(s) \geq f(s_\mr{opt}) &pour de la minimisation
    \end{cases*}$$
\end{definition}

\newcommand{\sopt}[0]{s_\mr{opt}}
\newcommand{\sapprox}[0]{s_\mr{approx}}



\begin{definition}{6.8}{algorithmes de résolution exacte, d'approximation}
    Pour un problème d'optimisation, pour une instance $i \in I$, 
    \begin{enumeratebf}
        \item un algorithme de résolution exacte est un algorithme qui renvoie $\sopt \in S_i$
        \item un algorithme d'approximation est un algorithme qui renvoie \notion{$\sapprox \in S_i$ une solution approximativement optimale}. On définit alors \notion{$\rho_i(\sapprox)$ le rapport de performance pour l'instance $i$ de $\sapprox$} comme valant~:
        $$\rho_i(\sapprox) = \max\Bigg(\frac{f(\sapprox)}{f(\sopt)},\, \frac{f(\sopt)}{f(\sapprox)}\Bigg)\quad(\geq 1)$$
    \end{enumeratebf}  
\end{definition}

\begin{definition}{6.9}{rapport de performance pour un algorithme}
    Pour un problème d'optimisation impliquant un algorithme $\mc{A}$ d'approximation,  on dit que \notion{$\rho_n$ est un rapport de performance pour une instance de taille $n$} si~:
    $$ \rho_n \geq \sup_{\substack{i \in I \\ \abs{i} = n}} \rho_i\Big(\mc{A}(i)\Big)$$
    On dit alors que \notion{$\mc{A}$ est une $\rho_n$-approximation}.
    Généralement, on cherche un majorant de cette borne supérieure.
\end{definition}

\begin{definition}{6.10}{arbre de recherche de solutions}
    Dans le cadre d'un problème d'optimisation combinatoire, étant donnée $i \in I$ un instance, on appelle \notion{arbre de recherche de solutions de $i$} un arbre étiqueté par des parties de $S_i$~:
    \begin{itemize}
        \item la racine est étiquetée par $S_i$ tout entier
        \item chaque noeud étiqueté par $S \subset S_i$ a pour fils des noeuds d'étiquette $S_{\mr{f}_1},\, \dots,\, S_{\mr{f}_k}$ tels que $\displaystyle S = \bigsqcup_{i=1}^k S_{\mr{f}_i}$
        \item les feuilles sont étiquetées par des singletons, on les associe en fait à une solution chacune.
    \end{itemize}
    On définit alors une \notion{fonction $\varphi$ d'évaluation} qui à un noeud $s$ d'étiquette $S$ associe ce qu'on peut espérer au mieux dans l'exploration du sous-arbre~:
    $$\begin{cases*}
    \displaystyle \varphi(n) \geq \max_{s \in S} f(s) &pour de la maximisation\\
    \displaystyle \varphi(n) \leq \min_{s \in S} f(s) &pour de la minimisation
    \end{cases*}$$

\end{definition}

\begin{definition}{6.10}{algorithme par séparation-évaluation}
    Un \notion{algorithme par séparation évaluation (Branch \& Bound)} repose \notion{une fonction d'évaluation $\varphi$} et sur trois règles~:
    \begin{enumeratebf}
        \item \notion{règle de sélection} : impose un ordre d'exploration des fils de chaque sous-arbre de recherche de solutions
        \item \notion{règle de séparation} : impose la méthode de partitionnement de chaque étiquette des noeuds de l'arbre de recherche de solutions
        \item \notion{règle d'évaluation} : impose de ne pas explorer certains fils.
    \end{enumeratebf}
\end{definition}

\begin{implementation}{algorithme générique par séparation-évaluation (cadre de la maximisation)}
    Pour tout arbre $\mc{A}$ de recherche de solution, on note $S(\mc{A})$ son étiquette.
    \begin{itemize}
        \item \textbf{Entrée} :
        \begin{itemize}
            \item $S$ un ensemble de solutions possibles
            \item $\varphi : \mc{P}(S) \to \R_+$ une fonction d'évaluation
            \item $f$ la fonction de coût du problème, ici supposée à maximiser
        \end{itemize}
        \item \textbf{Sortie} : $\sopt \in S$ telle que $\forall s \in S,\, f(\sopt) \geq f(s)$
    \end{itemize}
    \begin{lstLNat}
    separation_evaluation($S$, $\varphi$, $f$):
        $\mc{A}$ = arbre feuille de racine d'étiquette $S$
        initialiser un sac contenant $\mc{A}$
        $\sopt$ = None // noeud courant
        max = $-\infty$ // coût courant
        tant que le sac n'est pas vide:
            $n$ = pop le premier élément du sac // règle de sélection
            si $\abs{S(n)}$ == 1:
                identifier $\{s\}$ = $S(n)$
                si $f(s)$ > max:
                    $\sopt$ = $s$
                    max = $f(s)$
            sinon si $\varphi\big(S(n)\big)$ > max: // règle d'évaluation
                partitionner $S(n)$ = $\bigsqcup_{i=1}^{k}S_i$ // règle de séparation
                pour tout $i \in \intint{1}{k}$:
                    ajouter à $n$ le fils $f_i$ d'étiquette $S_i$
                    ajouter $f_i$ au sac
        renvoyer $\sopt$

    \end{lstLNat}
\end{implementation}

\begin{definition}{6.11}{relaxation d'un problème d'optimisation}
    On appelle \notion{relaxation d'un problème d'optimisation $\mc{P}$} un problème $\mc{P}'$ construit à partir de $\mc{P}$ en omettant une ou plusieurs contraintes. $\mc{P}'$ comporte alors de la même fonction de coût, les mêmes instances, mais l'ensemble des solutions possibles est plus grand pour l'inclusion.
\end{definition}

\begin{definition}{6.12}{généralisation d'un problème d'optimisation}
    On appelle \notion{généralisation d'un problème d'optimisation $\mc{P}$}  un problème $\mc{P}'$ tel que~:
    \begin{itemize}
        \item les deux ont la même fonction de coût, avec le même objectif (maximisation ou minimisation)
        \item $I_\mc{P} \subset I_{\mc{P}'}$
        \item pour toute instance de $I_{\mc{P}}$, une solution optimale pour $\mc{P}'$ est une solution optimale pour $\mc{P}$.
    \end{itemize}
    
\end{definition}

\input{../../stock/pied.tex}