\input{../../stock/en-tete_v4.tex}
\begin{document}
\begin{adjustwidth}{-3cm}{-3cm}
\input{../../stock/commands.tex}

\begin{definition}{6.1}{algorithme probabiliste}
    Un algorithme est dit \notion{probabiliste} s'il effectue au moins un \notion{choix aléatoire entraînant une variation comportementale}.
\end{definition}

\begin{definition}{6.2}{algorithme déterministe}
    Un algorithme est dit \notion{déterministe} s'il est non probabiliste : son comportement est toujours le même pour une même entrée.
\end{definition}

\begin{definition}{6.3}{algorithme de Las Vegas}
    Un algorithme probabiliste est dit \notion{de Las Vegas} si : 
    \begin{itemize}
        \item il renvoie toujours une solution correcte ;
        \item son temps d'exécution est régi par une variable aléatoire.
    \end{itemize}
\end{definition}

\begin{definition}{6.4}{loi géométrique}
    Une \notion{loi géométrique de paramètre $p$} est une loi modélisant le \notion{nombre d'essais nécessaires jusqu'au premier succès} dans une suite d'expériences indépendantes identiques. Si $X$ suit une loi géométrique, alors~:
    $$\forall k \in \N^*,\, \mb{P}(X = k) = (1-p)^{k-1} p$$
    On a alors $\displaystyle \mb{E}(X) = \frac{1}{p}$ et $\displaystyle \mb{V}(X) = \frac{1-p}{p^2}$.
\end{definition}

\begin{implementation}{exemple d'algorithme de Las Vegas}
    \begin{lstC}
    int las_vegas(int* t, int taille){
        while(true) {
            int k = rand() % taille;
            if (t[k] == 1){
                return k;
            }
        }
    }
    \end{lstC}
\end{implementation}

\begin{definition}{6.5}{algorithme de Monte Carlo}
    Un algorithme probabiliste est dit \notion{de Monte Carlo} si~: 
    \begin{itemize}
        \item il renvoie sous une certaine probabilité une solution correcte ;
        \item son temps d'exécution est constant, indépendant des choix aléatoires. 
    \end{itemize}
\end{definition}

\begin{implementation}{exemple d'algorithme de Monte Carlo}
    \begin{lstC}
    int monte_carlo(int* t, int taille) {
        for (int i = 0; i < 300; i++){
            int k = rand() % taille;
            if (t[k] == 1){
                return k;
            }
        }
        return -1;
    }
    \end{lstC}
\end{implementation}

\begin{definition}{6.6}{deux types d'algorithmes Monte Carlo pour un problème de décision}
    Pour un problème de décision (dont la réponse est Vrai ou Faux), on distingue deux catégories d'algorithmes Monte Carlo~: 
    \begin{enumeratebf}
        \item \notion{À erreur unilatérale} : pour toute entrée de sortie attendue Vrai, l'algorithme renvoie Vrai presque sûrement (avec une probabilité de 1) et pour une entrée de sortie attendue Faux, l'algorithme renvoie Vrai avec une probabilité non nulle.
        \item \notion{À erreur bilatérale} : il existe une entrée de sortie attendue Vrai, pour laquelle l'algorithme renvoie Faux avec une probabilité non nulle.
    \end{enumeratebf}
\end{definition}

\begin{definition}{6.7}{problème d'optimisation}
    Un problème d'optimisation est défini pour un \notion{ensemble $I$ d'instances} : les entrées possibles. \\
    À toute instance $i \in I$ on associe un \notion{ensemble $S_i$ de solutions possibles}. \\
    À un problème d'optimisation on peut définir une \notion{fonction $f:\bigcup_{i \in I} \to \R_+$ de coût} que l'on cherche soit à minimiser soit à maximiser.\\\\
    Pour une instance $i \in I$, on cherche $s_\mr{opt} \in S_i$ une solution au coût optimal~:
    $$\begin{cases*}
        \forall s \in S_i,\, f(s) \leq f(s_\mr{opt}) &pour de la maximisation \\
        \forall s \in S_i,\, f(s) \geq f(s_\mr{opt}) &pour de la minimisation
    \end{cases*}$$
\end{definition}

\newcommand{\sopt}[0]{s_\mr{opt}}
\newcommand{\sapprox}[0]{s_\mr{approx}}



\begin{definition}{6.8}{algorithmes de résolution exacte, d'approximation}
    Pour un problème d'optimisation, pour une instance $i \in I$, 
    \begin{enumeratebf}
        \item un algorithme de résolution exacte est un algorithme qui renvoie $\sopt \in S_i$
        \item un algorithme d'approximation est un algorithme qui renvoie \notion{$\sapprox \in S_i$ une solution approximativement optimale}. On définit alors \notion{$\rho_i(\sapprox)$ le rapport de performance pour l'instance $i$ de $\sapprox$} comme valant~:
        $$\rho_i(\sapprox) = \max\Bigg(\frac{f(\sapprox)}{f(\sopt)},\, \frac{f(\sopt)}{f(\sapprox)}\Bigg)\quad(\geq 1)$$
    \end{enumeratebf}  
\end{definition}

\begin{definition}{6.9}{rapport de performance pour un algorithme}
    Pour un problème d'optimisation impliquant un algorithme $\mc{A}$ d'approximation,  on dit que \notion{$\rho_n$ est un rapport de performance pour une instance de taille $n$} si~:
    $$ \rho_n \geq \sup_{\substack{i \in I \\ \abs{i} = n}} \rho_i\Big(\mc{A}(i)\Big)$$
    On dit alors que \notion{$\mc{A}$ est une $\rho_n$-approximation}.
    Généralement, on cherche un majorant de cette borne supérieure.
\end{definition}

\input{../../stock/pied.tex}