\input{../../stock/en-tete_v4.tex}
\begin{document}
\begin{adjustwidth}{-3cm}{-3cm}
\input{../../stock/commands.tex}
\newcounter{chapitre}
\setcounter{chapitre}{8}

\section{Fils d'exécution}

\begin{definition}{}{processus}
    Un \notion{processus} est un programme en cours d'exécution. Il occupe la mémoire selon l'organisation suivante~
    \begin{itemize}
        \item le \notion{segment de données}, qui constitue une zone de mémoire "fixe" pour stocker les variables globales, ainsi que les constantes.
        \item le \notion{tas}, où sont stockées les variables allouées dynamiquement.
        \item la \notion{pile}, une zone de mémoire de taille variable où sont stockés~:
        \begin{itemize}
            \item les \notion{blocs d'activation} pour chaque appel de fonction contenant les variables locales aux fonctions.
            \item un \notion{pointeur d'instruction} vers le segment de code qui contient l'adresse de la prochaine instruction dans le \notion{segment de code}.
        \end{itemize}
        \item le \notion{segment de code}, où sont stockés les instructions du programme.
    \end{itemize}
\end{definition}

\begin{remarque}{}{contexte d'un processus}
    Deux processus ne partagent pas leur zone de mémoire. Pour communiquer, ils doivent effectuer des \notion{appels système} (interaction avec du matériel physique comme la mémoire ou les périphériques) coûteux. Pour cette raison on dit que \notion{le contexte d'un processus est lourd}.
\end{remarque}

\begin{remarque}{}{}
    Pour les faire communiquer, on a besoin de faire des \notion{appels système}. Par exemple, on utilise un fichier utilisé par deux processus en lecture/écriture.
\end{remarque}

\begin{remarque}{}{}
    On dit que le \notion{contexte d'un processus} est \notion{lourd} car sa création est son activation sont coûteux.
\end{remarque}

\begin{definition}{}{fil d'exécution (thread)}
    Un \notion{fil d'exécution} (dit \textit{thread}) est une séquence d'\notion{instructions atomiques} : instructions s'effectuant individuellement sans interruption. On le définit par~:
    \begin{itemize}
        \item sa \notion{tâche}, sous la forme d'une fonction.
        \item une pile listant les intructions atomiques à traîter.
    \end{itemize}
    Un processus peut contenir plusieurs fils d'exécutions dont un désigné \notion{principal}.
\end{definition}

\begin{remarque}{}{création d'un fil d'exécution}
    Pour créer un fil d'exécution, on définit sa \notion{tâche} sous la forme d'une fonction et on lui associe une pile listant les instructions à traîter.
\end{remarque}

\begin{remarque}{}{}
    Un processus peut contenir plusieurs fils d'exécutions~:
    \begin{itemize}
        \item un désigné \notion{principal}
        \item tous ceux créés en plus : on a autant de piles dans la mémoire que de fils d'exécution.
    \end{itemize}
    voir figure 
\end{remarque}

\begin{remarque}{}{contexte d'un fil d'exécution}
    Les fils d'exécution peuvent partager des données stockées dans le tas ou le segment de données. Ainsi, on dit que le \notion{contexte} des fils d'exécution est \notion{léger} car la création, l'activation et la communication est facilitée et peu coûteuse.\\
    Pour autant, les fils d'exécution s'exécutent indépendamment les uns des autres.
\end{remarque}

Plusieurs fils d'exécution peuvent partager des données stockées dans le tas ou le segment de données.

Théoriquement, ils ont accès avec les adresses mémoires aux piles des autres fils, mais ce n'est pas utilisé en pratique.

On dit que le \notion{contexte} des fils d'exécution est \notion{léger} car la création, l'activation et la communication est facilitée et peu coûteuse.

Les fils d'exécutions s'exécutent indépendamment les uns les autes.

\begin{definition}{}{programmes séquentiel, concurrent}
    Un \notion{programme séquentiel} est un programme utilisant un seul fil d'exécution. Un \notion{programme concurrent} en utilise plusieurs à la fois.
\end{definition}

Un fil seul est \notion{séquentiel}. On dit qu'un programme est \notion{concurrent} lorsqu'il a plusieurs fils d'exécution (concurrent au sens de "se passe en même temps").

L'exécution repose sur un \notion{entrelacement} \notion{non déterministe} des fils d'exécution.

Dans un programme concurrent, initialement on a un fil d'exécution principal, puis on a des phases avec plusieurs fils d'execution en parallèle. Il faut explicitement attendre la terminaison des \notion{fils secondaires} pour revenir à un unique fil principal avant la fin du processus. Voir Fig.2 \\
Si on n'attend pas explicitement, des fils secondaires peuvent ne pas avoir terminé leur \notion{tâche} au moment où le fil principal termine le processus.

\begin{implementation}{exemple de programme concurrent en pseudocode}
    \code{t} pour tâche.
    \begin{lstLNat}
    $F$(nom):
        pour i=1 jusqu'à 10:
            afficher nom
            afficher i
    MAIN(): // programme concurrent
        t1 = création du fil 1 réalisant la tâche $F$ sur "Fil 1"
        t2 = création du fil 2 réalisant la tâche $F$ sur "Fil 2"
        attendre la fin de t1
        attendre la fin de t2
        afficher "Fin"
    \end{lstLNat}
    On a trois fils d'exécutions en parallèle~:
    \begin{itemize}
        \item un pour la fonction \code{MAIN} (le \notion{fil principal})
        \item le fil 1 pour $F$ sur "Fil1"
        \item le fil 2 pour $F$ sur "Fil2"
    \end{itemize}
\end{implementation}

On a plusieurs résultats possibles, issus de différents entrelacements.\\

À chaque exécution, on peut avoir une issue différente : c'est \notion{non déterministe}.



\begin{exemple}{}{}
    voir feuilles
\end{exemple}

\begin{exemple}{}{}
    voir feuilles
\end{exemple}

En C, pour pouvoir créer des fils d'exécution, il est nécessaire d'inclure l'en-tête~:
$$\code{\#include <pthread.h>}$$
permettant l'utilisation de la bibliothèque POSIX \code{pthread}.\\
De plus, à la compilation, il faut ajouter l'option de compilation~:
$$\code{-pthread}$$

On a un type décrivant les fils d'exécution~:
$$\code{pthread\_t}$$
\\\\\\\\\\
Pour créer un fil d'exécution, on utilise la fonction de prototype suivant~:
\begin{lstC}
    int pthread_create(
        pthread_t* thread,
        const pthread_attr_t* attr,
        void* (*start_routine)(void*), //transtypage
        void* arg
    );
\end{lstC}

Avant d'appeler \code{pthread\_create}, il faut créer un pointeur du type \code{pthread\_t*} valide (la mémoire est allouée avant appel, mais avoir défini sur la pile convient, auquel cas on y rentre \code{\&file}, car il lui faut quand même un pointeur, cf exemple ci-dessous).\\
On déclare un fil~:
\begin{lstC}
    pthread_t t1; // alloué sur la pile ici
    pthread_create(&t1, $\dots$); // et on y met le pointeur
\end{lstC}



\begin{remarque}{}{concernant le paramètre \code{*start\_routine}}
    On écrit préalablement une fonction \code{start\_routine} qui correspond à la tâche du fil créé et qui doit être du prototype~:
    \begin{lstC}
        void* start_routine(void* arg)
    \end{lstC}
    Bien qu'on ait un unique argument de type \code{void*}, grâce au transtypage et à l'utilisation de structures bien choisies, on peut pallier à cette restriction. De même pour le retour de la fonction $\code{start\_routine}$.\\
    Néammoins, en MPI, on ne récupère pas la sortie : en pratique, on écrit dans des variables partagées entre les fils (merci les pointeurs !).\\
    Théoriquement, la fonction prend un pointeur vers une fonction, mais les deux syntaxes fonctionnent (attention au sujet dans ce cas).
    \begin{lstC}
        pthread_create(&t1, $\dots$, start_routine, $\dots$);
        pthread_create(&t1, $\dots$, &start_routine, $\dots$);
    \end{lstC}
\end{remarque}

\begin{remarque}{}{concernant le paramètre \code{void* arg}}
    \code{arg} est l'argument que l'on donne à la fonction \code{start\_routine} pour le fil créé.\\
    Il vaut \code{NULL} si aucun argument n'est à transférer.
\end{remarque}

\begin{remarque}{}{concernant le paramètre \code{const pthread\_attr\_t* attr}}
    En MPI, il vaut \code{NULL}.
\end{remarque}

\begin{remarque}{}{concernant la sortie de \code{pthread\_create}}
    La valeur de retour de \code{pthread\_create} est un entier~:    
    \begin{itemize}
        \item \code{0} si tout se passe bien.
        \item un code d'erreur sinon.
    \end{itemize}
    Mais en MPI, on ignore cette sortie.
\end{remarque}

Pour attendre la fin de l'exécution d'un fil dans un autre, (pas forcément dans le \notion{fil principal}), on utilise la fonction~:\\
\begin{lstC}
    int pthread_join(
        pthread_t thread,
        void** value_ptr
    );
\end{lstC}

\begin{remarque}{}{paramètre \code{thread}}
    \code{thread} est le fil dont on attend la terminaison. En MPI, \code{value\_ptr} est toujours \code{NULL}.
\end{remarque}

\begin{definition}{}{synchronisation, et pratique}
    La \notion{synchronisation} permet de coordonner l'exécutions des fils d'exécution afin qu'ils puissent travailler ensemble de façon cohérente.\\
    En C comme en OCaml, la fonction de synchronisation permet de bloquer l'exécution de la fonction principale (dans laquelle la fonction est appelée) pour finir l'exécution du fil d'exécution passé en argument.
\end{definition}


\begin{implementation}{implémentation en C d'une démonstration de l'entrelacement non déterministe}
    \begin{lstC}
        #include <pthread.h>
        #include <stdio.h>

        void* F(void* arg){ // au lieu de char* str, on GÉNÉRALISE en y 
        // mettant directement le arg qu'on rentre dans la création du thread !
            char* chaine = (char*) arg;
            for (int i=0; i<1000; i++){
                printf("%s %d\n", chaine, i);
            }
            return NULL; // important !
        }

        int main(){
            pthread_t t1, t2;
            pthread_create(&t1, NULL, &F, "Fil1");
            pthread_create(&t2, NULL, &F, "Fil2");
            pthread_join(t1, NULL);
            pthread_join(t2, NULL);
            printf("Fin");
            return 0;
        }
    \end{lstC}
\end{implementation}

En OCaml, on utilise le module \code{Thread}.
Cela ne fonctionne pas en mode interactif, il faut compiler-exécuter avec des options de compilation.
$$\code{ocamlc -I +threads unix.cma threads.cma ficher.ml -o fichier}$$
$$\code{ocamlopt -I +threads unix.cmxa threads.cmxa ficher.ml -o fichier}$$
Le type des fils d'exécution est~:
$$\code{Thread.t}$$
Pour créer un fil d'exécution~:
\begin{lstOCaml}
    Thread.create : ('a -> 'b) -> 'a -> Thread.t
\end{lstOCaml}
\code{Thread.create f x} crée et "renvoie" un fil d'exécution que réalise la fonction \code{f} sur l'argument \code{x}.\\\\
Pour attendre la terminaison d'un fil dans un autre~:
\begin{lstOCaml}
    Thread.join : Thread.t -> unit
\end{lstOCaml}

\begin{implementation}{implémentation en OCaml d'une démonstration de l'entrelacement non déterministe}
    \begin{lstOCaml}
        let f chaine = 
            for i=0 to 1000 do
                print_string (chaine^(string_of_int i)^"\n");
            done

        let t1 = Thread.create f "File 1 : "
        let t2 = Thread.create f "File 2 : "
        let () = Thread.join t1; Thread.join t2
        let () = print_string "Fin"
    \end{lstOCaml}
\end{implementation}

\section{Synchronisation et concurrence}

\subsection{Pourquoi faut-il synchroniser ?}

Pour que les fils coopèrent sur des variables partagées, il faut leur permettre de communiquer.

\begin{implementation}{deux fils d'exécutions communiquantes en C}
    On écrit un programme qui utilisent deux fils d'exécution qui incrémentent un \notion{entier commun}.
    \begin{lstC}
        void* f(void* arg){
            for (int i=0; i<1000; i++){
                *((int*) arg) = *((int*) arg) + 1; // déréférencement
            }
            return NULL;
        }
        int main(){
            int x = 0;
            pthread_t t1, t2;
            pthread_create(&t1, NULL, &f, (void*) &x);
            pthread_create(&t2, NULL, &f, (void*) &x); // l'entier x est une varible partagée

            pthread_join(t1, NULL); // demande d'attendre t1
            pthread_join(t2, NULL); // demande d'attendre t2
            printf("x = %i \n",x);
            return 0;
        }
    \end{lstC}
    On s'attend à l'affichage de $\code{"x = 2000"}$, mais en pratique c'est plus petit.
\end{implementation}
    

l'incrémentation n'est pas une instance atomique~:
\begin{itemize}
    \item on a une phase de récupération de la valeur
    \item on a une phase d'incrémentation locale de la valeur récupérée (espace mémoire temporaire dédié)
    \item on a une dernière phase où l'on écrit la nouvelle valeur dans l'espace mémoire dédié.
\end{itemize}
Dans l'entrelacement, le fil actif peut changer entre deux phases. Donc la valeur écrite dans la dernière phase peut être inférieure à la valeur. Voir Fig.3

\subsection{Gestion des sections critiques}

\begin{definition}{}{section critique (d'après le cours)}
    Une \notion{section critique} est une suite d'instructions d'un processus nécessitant d'accéder à une ressource unique et commune à plusieurs fils d'exécution. On parle de \notion{variable partagée}.
\end{definition}

\begin{definition}{}{section critique}
    Une \notion{section critique} est une suite d'instructions que jamais plus d'un thread ne doit exécuter simultanément.\\
    Lorsqu'un fil accède à une section critique, on dit qu'il entre en \notion{exclusion mutuelle} sur la ressource~: il empêche tous les autres d'y accéder.
\end{definition}

\textbf{Enjeu} : Un seul fil doit être capable d'accéder à une section critique pour une même ressource, en lecture ou en écriture. \\\\

Pour assurer cela, on peut protéger la ressource partagée avec un \notion{verrou} que l'on peut sceller ou lever pour limiter l'accès aux sections critiques dans les différents fils. On dit qu'un fil qui est le seul à accéder à une section critique est en exclusion mutuelle.

\begin{definition}{}{exclusion mutuelle}
    Lorsqu'un fil accède à une section critique, on dit qu'il entre en \notion{exclusion mutuelle} sur la ressource : il empêche tous les autres d'y accéder.
\end{definition}

\begin{definition}{}{course critique}
    Lorsque deux fils cherchent à accéder à une même ressource et que plusieurs entrelacements donnent une issue différente, on parle de \notion{course critique}.
\end{definition}

Lorsque deux fils cherchent à accéder à une même ressources et que deux entrelacements au moins donnent deux résultats différents, on parle de \notion{course critique}.

\begin{remarque}{}{concernant l'exemple de l'incrémentation mutuelle}
    Dans l'exemple de la section 2.1, on obtient différentes valeurs pour la variable commune : il s'agit d'une course critique.\\
    On cherche à éviter les courses critiques car elles causent un comportement non déterministe.
\end{remarque}

\begin{definition}{}{propriétés usuelles d'un programme concurrent}
    Pour un programme concurrent, on cherche à garantir plusieurs propriétés~:
    \begin{enumeratebf}
        \item \notion{sûreté (ou principe de l'exclusion mutuelle)} : On a au plus un fil d'exécution accédant une section critique pour une même ressource au même moment.
        \item \notion{vivacité (ou absence de famine)}~: tout fil d'exécution demandeur d'accès à une ressource partagée aura à un moment donné accès à la ressource.
        \item \notion{absence d'inter-blocage}~: lorsque plusieurs fils demandent accès à une ressource partagée simultanément, au moins un obtient l'accès.
    \end{enumeratebf}
\end{definition}
\textbf{N.B} : la troisième est moins forte (difficile à réaliser) que la deuxième (2 implique 3), on la met car parfois on veut juste vérifier la troisième.\\

\begin{remarque}{}{atomicité d'une section critique}
    L'atomicité d'une section critique est importante. La mise en place de verrou de la forme suivante permet d'induire une atomicité de la section critique~:
    \begin{lstLNat}
        lock()
        // section critique
        unlock()
    \end{lstLNat}
\end{remarque}

\begin{exemple}{}{de verrouillage}
    \begin{center}
        \begin{tabular}{c|c}
            \textbf{Fil 1} & \textbf{Fil 2} \\
            \code{t = x}         & \code{u = x}   \\ 
            \code{x = t+1}         & \code{x = u+2}          \\ 
        \end{tabular}
    \end{center}
    La variable \code{x} est une ressource partagée. Les deux morceaux sont des \notion{sections critiques pour la ressource \code{x}}.\\
    Dans l'état actuel, on a une course critique car les deux entrelacements donnent des résutlats différents~:
    \begin{center}
        \begin{tabular}{c|c}
            \textbf{Fil 1} & \textbf{Fil 2} \\
            \code{t = x}         &    \\ 
            \code{x = t+1}         &         \\ 
            & \code{u = x}  \\
            & \code{x = u+2}  
        \end{tabular}
    \end{center}
    La valeur de la variable \code{x} est augementée de 3.
    \begin{center}
        \begin{tabular}{c|c}
            \textbf{Fil 1} & \textbf{Fil 2} \\
            \code{t = x}         &    \\ 
                     &   \code{u = x}     \\ 
            &   \code{x = u+2} \\
            \code{x = t+1} &   
        \end{tabular}
    \end{center}
    La valeur de la variable \code{x} est incrémentée.
\end{exemple}

\begin{remarque}{}{trace d'exécution}
    On peut parler de \notion{trace d'exécution} lorsque l'on donne un entrelacement possible.
\end{remarque}

\begin{exemple}{}{élimination de section critique}
    Pour ne plus avoir de section critique, on met en place un verrou \code{m}.
    \begin{center}
        \begin{tabular}{c|c}
            \textbf{Fil 1} & \textbf{Fil 2} \\
            \code{lock(m)} & \code{lock(m)} \\
            \code{t = x} & \code{u = x}\\
            \code{x = t+1} & \code{x = u+2}\\
            \code{unlock(m)} & \code{unlock(m)}
        \end{tabular}
    \end{center}
    Le premier fil à lire l'instruction \code{lock(m)} verrouille \code{m}, le second attend alors que \code{m} soit déverrouillé pour lire la prochaine instruction.
\end{exemple}

\begin{definition}{}{mutex}
    On met en place des verrous à l'aide de \notion{mutex} qui disposent de deux opérations élémentaires~:
    \begin{itemize}
        \item une opération de \notion{verrouillage}~: verrouille le mutex s'il est déverrouillé, ou bien attend que le mutex soit déverrouillé puis le verrouille.
        \item une opération de \notion{déverrouillage}~: déverrouille le mutex.
    \end{itemize}
    On dit qu'un mutex est une \notion{primitive de synchronisation}, car c'est un outil utilisant des instructions simples pour gérer la synchronisation des fils d'exécutions.
\end{definition}

\begin{remarque}{}{usage de mutex en pratique}
    Dans certains langages (dont OCaml), un mutex doit être verrouillé puis déverrouillé dans un même fil. Cela reste une bonne pratique dans les autres langages.\\
    Lorsqu'on souhaite verrouiller dans un fil et déverrouiller dans un autre, on préfèrera l'utilisation de \notion{sémaphores}~: une généralisation des mutex.
\end{remarque}

\begin{definition}{}{sémaphores binaire, à compteur}
    Il existe deux types de \notion{sémaphores}~:
    \begin{itemize}
        \item les \notion{sémaphores binaires} : ce sont des mutex
        \item les \notion{sémaphores à compteur} : une sutructre de données constituée d'un \notion{compteur} et d'une \notion{file d'attente}.
    \end{itemize}
    On initialise un sémaphore à compteur avec une file d'attente vide et un compteur initialisé à un entier positif.\\
    Le sémaphore à compteur exploite deux opérations élémentaires~:
    \begin{itemize}
        \item \notion{demande d'accès}~: notée \code{P} ou bien \code{down} (\code{wait} en C, \code{acquire} en OCaml).\\
            On vérifie que le compteur est strictement positif~
            \begin{itemize}
                \item si oui, one le décrémente et on passe à l'instruction suivante.
                \item sinon, on attend que le compteur soit incrémenté pour un autre fil et lui applique le cas précédent dès que ça arrive.
            \end{itemize}
            pendant qu'il attend, le fil d'exécution est placé dans la file d'attente du sémphore à compteur.
            \item \notion{fin d'accès}~: notée \code{V} ou bien \code{vp} (\code{post} en C, \code{release} en OCaml)\\
            Le compteur est incrémenté et si la file d'attente n'est pas vide, un des fils de la file d'attente du sémaphore (à compteur) est "réveillé" pour décrémenter le compteur et poursuivre l'exécution du dit fil. \textbf{les fils sont donc réveillés dans un ordre non déterministe}.
    \end{itemize}
    \textit{on fera un pseudocode de fonctionnement, la FC est lourde là}
\end{definition}

\begin{definition}{}{initialisation d'un sémaphore à compteur}
    On initialise un sémaphore à compteur avec~:
    \begin{itemize}
        \item une \notion{file d'attente} vide, qui stockera les fils concernés par le sémaphore.
        \item un \notion{compteur}, entier naturel non nul désignant le nombre maximal de fils pouvant accéder à la section critique protégée par le sémaphore.
    \end{itemize}
\end{definition}

\begin{implementation}{demande d'accès à un sémaphore}
    On note $\mc{S}$ le sémaphore. le fil \code{fil} est celui dans lequel \code{P} est appelée.
    \begin{lstLNat}
    P($\mc{S}$, fil):
        si $\mc{S}$.compteur <= 0: 
            // $\mc{S}$ : "Je ne peux pas vous donner l'accès, je garde votre nom."
            ajouter($\mc{S}$.file, fil)
            bloquer(fil) // $\code{fil}$ : "Ok, j'attends."
        $\mc{S}$.compteur = $\mc{S}$.compteur - 1 // un emplacement libre de moins
    \end{lstLNat}
\end{implementation}

\begin{implementation}{annonce de fin d'accès à un sémaphore}
    On note $\mc{S}$ le sémaphore.
    \begin{lstLNat}
    V($\mc{S}$):
        si $\mc{S}$.file n'est pas vide:
            fil = defiler($\mc{S}$.file) // $\mc{S}$ : "C'est à vous, $\code{fil}$."
            réveiller(fil) // $\code{fil}$ : "Entendu, c'est reparti."
        $\mc{S}$.compteur = $\mc{S}$.compteur + 1 // un emplacement de libéré
    \end{lstLNat}
\end{implementation}

\begin{remarque}{}{rôle du compteur du sémaphore à compteur}
    Le compteur joue un rôle de \notion{compteur de ressources}.\\
    La demande d'accès correspond à la récupération d'une ressource pour passer à la suite~: on attend s'il n'y en a pas de disponible.\\
    La fin d'accès correspond à la situation où l'on rend disponible une ressource.
\end{remarque}

\begin{remarque}{}{comparaison entre sémaphores à compteur et mutex}
    Les sémaphores sont moins restrictifs que les mutexs : on peut avoir des fils qui font uniquement de la demande d'accès et des fils qui font uniquement de la fin d'accès (production de ressources).
\end{remarque}

\begin{remarque}{}{initialisation du compteur d'un sémaphore à compteur}
    On peut voir dans certaines situations la valeur du compteur initiale comme le nombre maximum souhaité de fils qui peuvent exploiter les ressources partagées simultanément.
\end{remarque}

\subsection{Mutex et sémaphores à compteurs en C}

L'utilisation des mutex se fait à l'aide de la bibliothèque \code{pthread.h}. Le type utilise pour les mutex est~:
$$\code{pthread\_mutex\_t}$$
On iniatialise un mutex déverrouillé de la façon suivante (pour l'avoir verrouillé direct, on le verrouille aussitôt après)~:
\begin{lstC}
    pthrad_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
\end{lstC}
Si la variable protégée est une variable globale, le mutex doit être aussi une variable globale (définie sur le segment de données).
On ensuite trois fonctions à connaître~:
\begin{itemize}
    \item \notion{verrouillage}~:
    \begin{lstC}
        int pthread_mutex_lock(pthread_mutex_t* mutex);
    \end{lstC}
    L'instruction \code{pthread\_mutex\_lock(&m)} verrouille \code{m} et renvoie 0 si tout s'est bien passé.
    \item \notion{déverrouillage}~:
    \begin{lstC}
        int pthread_mutex_unlock(pthread_mutex_t* mutex);
    \end{lstC}
    L'instruction \code{pthread\_mutex\_unlock(&m)} déverrouille \code{m} et renvoie 0 si tout s'est bien passé.
    \item \notion{destruction}~:
    \begin{lstC}
        int pthread_mutex_destroy(pthread_mutex_t* mutex)
    \end{lstC}
    L'instruction \code{pthread\_mutex\_destroy(&m)} détruit \code{m} (il ne peut plus être utilisé) et renvoie 0 si tout s'est bien passé.
\end{itemize}

L'utilisation des sémaphores demande l'inclusion du fichier d'en-tête \code{semaphore.h}~:
\begin{lstC}
    #include <semaphore.h>
\end{lstC}
Le type utilisé pour les sémaphores~: est \code{sem\_t}. On a ensuite quatre fonctions à connaître~:
\begin{enumeratebf}
    \item \notion{Initialisation}~:
    \begin{lstC}
    int sem_init(
        sem_t* sem,
        int pshared,
        unsigned int value,
    );
    \end{lstC}
    On déclare préalablement notre sémaphore et on l'initialise~:
    \begin{lstC}
    sem_t s;
    sem_init(&s, 0, nmb)
    \end{lstC}
    avec \code{nmb} la valeur positive que l'on veut pour le compteur initialement (peut être 0).\\
    \code{pshared} vaut 0 pour signifier que tous les fils partagent les sémaphores. Tout autre valeur relèverait du hors programme.\\
    La valeur 0 est renvoyée si tout se passe bien.
    \item \notion{destruction}~:
    \begin{lstC}
    int sem_destroy(sem_t* sem);
    \end{lstC}
    \item \notion{demande d'accès (P, attente)}~: 
    \begin{lstC}
    int sem_wait(sem_t* sem);
    \end{lstC}
    \item \notion{fin d'accès (V, libération)}~:
    \begin{lstC}
    int sem_post(sem_t* sem);
    \end{lstC}
\end{enumeratebf}

\subsection{Mutex et sémaphores en OCaml}
Pour les mutex, on utilise en OCaml le module Mutex. Le type utilsé est \code{Mutex.t}. Trois fonctions à connaître~:
\begin{enumeratebf}
    \item \notion{création}~:
    \begin{lstOCaml}
    Mutex.create : unit -> Mutex.t
    \end{lstOCaml}
    \begin{lstOCaml}
    let m = Mutex.create ()
    \end{lstOCaml}
    \code{m} est un mute initialement déverrouillé
    \item \notion{verrouillage}~:
    \begin{lstOCaml}
    Mutex.lock : Mutex.t -> unit
    \end{lstOCaml}
    \code{Mutex.lock m} verrouille le mutex \code{m}
    \item \notion{déverrouillage}~:
    \begin{lstOCaml}
    Mutex.unlock : Mutex.t -> unit
    \end{lstOCaml}
    \code{Mutex.unlock m} déverrouille le mutex \code{m}.   
\end{enumeratebf}


\input{../../stock/pied.tex}